# Discrete Denoised Diffusion Probabilistic Models (DDPM) for Graphs

This project is the latest implementation of the corresponding Bachelors Thesis "Discrete DDPM for Graphs". 
The implementation is in Python and uses PyTorch as a framework.

## Installation
Use package manager Anaconda or Miniconda to generate a environment with the corresponding dependencies.
You may use the following command to do so: 
```bash
conda env create -f environment.yml
conda activate DISCDDPM
```
You should have activated your conda environment and are ready to run the project.

## Running the code
There are 3 different implementations of this project. For each implementation there exists a file used to train the model, a file used to sample the model and a file used to run a possible gridsearch over defined parameters as a Slurm job. The train and sample scripts are not meant to be initiated by the user directly. Use the corresponding gridsearch python file where you are able to set your slurm config and your model parameters to start any training.

### Running as a gridsearch Slurm job
This repository is meant to be run as a Slurm service, although it may theoretically also be run directly. For the Slurm service to work please configure the file scripts/gridsearch.sh to your Slurm specifications.
Depending on which of the three implementations you wish to run, open the according gridsearch_... file and edit your hyperparameters within the first paragraph as described in the comments.  Additionally you must change the line market with "ATTENTION" to match your Slurm serive command.   
This python script will iterate over all chosen hyperparameters as a gridsearch and generate config files in the directory "./config/gridsearch/consec_modelname_datetime/... ". These configs are generated based on the parameters in the template files (config/edp_final.yaml & config/ppgn_final.yaml) and the specified values in the gridsearch script. If you wish to change the standart parameters (train_until, sample_interval etc.) that are used for all runs, then do so in the mentioned template files. 

The gridsearch script will automatically generate additional files within the directories "./scripts/gridsearch/consec_modelname_datetime/" and ".gridsearchconsec_modelname_datetime/". The files in the scripts directory are the needed runnables for starting the Slurm jobs and the files in the .gridsearch directory store a single value, which indicates the Slurm job ID for later lookup.

This should be all you need to train and automatically sample.
All results of the training and the followed sampling (models, configs, output files etc. ) are stored in a newly generated directory  "./exp/modelname_dataname_month_time_randomnumber/..." . Additionally, if ran as a Slurm job, then you will have a .err and .out file in the directory ./slurm_log.

### Training directly as a Python Job
If you do not use Slurm then you may use the commands generated by the gridsearch scripts directly instead of writing them to a Slurm .sh file.

### Sampling 
If you wish to sample a already finished and trained model then you can do so manually with the jupyter notebook sample.ipynb. This also lets you print the sampled results over several noiselevels directly which is helpful for qualitative analysis of the results and the reverse process.



