| 07-01 16:47:52 EXPERIMENT BEGIN: 
| 07-01 16:47:52 logging into exp/gridsearch/ppgn_ego_18_small__Jul-01-16-47-52_123902/info.log
| 07-01 16:47:52 load dataset: ego_small
200
| 07-01 16:47:54 model: Powerful(
  (activation): LeakyReLU(negative_slope=0.01)
  (time_mlp): Sequential(
    (0): Linear(in_features=1, out_features=4, bias=True)
    (1): GELU()
    (2): Linear(in_features=4, out_features=1, bias=True)
  )
  (in_lin): Sequential(
    (0): Linear(in_features=2, out_features=128, bias=True)
  )
  (layer_cat_lin): Sequential(
    (0): Linear(in_features=1026, out_features=128, bias=True)
  )
  (convs): ModuleList(
    (0): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (1): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (2): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (3): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (4): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (5): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (6): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
    (7): PowerfulLayer(
      (m1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=128, out_features=128, bias=True)
      )
      (m4): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
      )
    )
  )
  (bns): ModuleList(
    (0): None
    (1): None
    (2): None
    (3): None
    (4): None
    (5): None
    (6): None
    (7): None
  )
  (feature_extractors): ModuleList(
    (0): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (1): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (2): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (3): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (4): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (5): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (6): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
    (7): FeatureExtractor(
      (lin1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
      )
      (lin2): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (lin3): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=False)
      )
      (activation): LeakyReLU(negative_slope=0.01)
    )
  )
  (after_conv): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
  )
  (final_lin): Sequential(
    (0): Linear(in_features=128, out_features=1, bias=True)
  )
)
| 07-01 16:47:54 Parameters: 
time_mlp.0.weight ........................................................................................... torch.Size([4, 1])
time_mlp.0.bias ................................................................................................ torch.Size([4])
time_mlp.2.weight ........................................................................................... torch.Size([1, 4])
time_mlp.2.bias ................................................................................................ torch.Size([1])
in_lin.0.weight ........................................................................................... torch.Size([128, 2])
in_lin.0.bias ................................................................................................ torch.Size([128])
layer_cat_lin.0.weight ................................................................................. torch.Size([128, 1026])
layer_cat_lin.0.bias ......................................................................................... torch.Size([128])
convs.0.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.0.m1.0.bias ............................................................................................ torch.Size([128])
convs.0.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.0.m1.2.bias ............................................................................................ torch.Size([128])
convs.0.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.0.m2.0.bias ............................................................................................ torch.Size([128])
convs.0.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.0.m2.2.bias ............................................................................................ torch.Size([128])
convs.0.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.0.m4.0.bias ............................................................................................ torch.Size([128])
convs.1.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.1.m1.0.bias ............................................................................................ torch.Size([128])
convs.1.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.1.m1.2.bias ............................................................................................ torch.Size([128])
convs.1.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.1.m2.0.bias ............................................................................................ torch.Size([128])
convs.1.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.1.m2.2.bias ............................................................................................ torch.Size([128])
convs.1.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.1.m4.0.bias ............................................................................................ torch.Size([128])
convs.2.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.2.m1.0.bias ............................................................................................ torch.Size([128])
convs.2.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.2.m1.2.bias ............................................................................................ torch.Size([128])
convs.2.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.2.m2.0.bias ............................................................................................ torch.Size([128])
convs.2.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.2.m2.2.bias ............................................................................................ torch.Size([128])
convs.2.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.2.m4.0.bias ............................................................................................ torch.Size([128])
convs.3.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.3.m1.0.bias ............................................................................................ torch.Size([128])
convs.3.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.3.m1.2.bias ............................................................................................ torch.Size([128])
convs.3.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.3.m2.0.bias ............................................................................................ torch.Size([128])
convs.3.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.3.m2.2.bias ............................................................................................ torch.Size([128])
convs.3.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.3.m4.0.bias ............................................................................................ torch.Size([128])
convs.4.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.4.m1.0.bias ............................................................................................ torch.Size([128])
convs.4.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.4.m1.2.bias ............................................................................................ torch.Size([128])
convs.4.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.4.m2.0.bias ............................................................................................ torch.Size([128])
convs.4.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.4.m2.2.bias ............................................................................................ torch.Size([128])
convs.4.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.4.m4.0.bias ............................................................................................ torch.Size([128])
convs.5.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.5.m1.0.bias ............................................................................................ torch.Size([128])
convs.5.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.5.m1.2.bias ............................................................................................ torch.Size([128])
convs.5.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.5.m2.0.bias ............................................................................................ torch.Size([128])
convs.5.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.5.m2.2.bias ............................................................................................ torch.Size([128])
convs.5.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.5.m4.0.bias ............................................................................................ torch.Size([128])
convs.6.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.6.m1.0.bias ............................................................................................ torch.Size([128])
convs.6.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.6.m1.2.bias ............................................................................................ torch.Size([128])
convs.6.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.6.m2.0.bias ............................................................................................ torch.Size([128])
convs.6.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.6.m2.2.bias ............................................................................................ torch.Size([128])
convs.6.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.6.m4.0.bias ............................................................................................ torch.Size([128])
convs.7.m1.0.weight ..................................................................................... torch.Size([128, 128])
convs.7.m1.0.bias ............................................................................................ torch.Size([128])
convs.7.m1.2.weight ..................................................................................... torch.Size([128, 128])
convs.7.m1.2.bias ............................................................................................ torch.Size([128])
convs.7.m2.0.weight ..................................................................................... torch.Size([128, 128])
convs.7.m2.0.bias ............................................................................................ torch.Size([128])
convs.7.m2.2.weight ..................................................................................... torch.Size([128, 128])
convs.7.m2.2.bias ............................................................................................ torch.Size([128])
convs.7.m4.0.weight ..................................................................................... torch.Size([128, 256])
convs.7.m4.0.bias ............................................................................................ torch.Size([128])
feature_extractors.0.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.0.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.0.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.0.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.1.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.1.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.1.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.1.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.2.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.2.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.2.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.2.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.3.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.3.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.3.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.3.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.4.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.4.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.4.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.4.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.5.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.5.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.5.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.5.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.6.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.6.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.6.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.6.lin3.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.7.lin1.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.7.lin1.0.bias ............................................................................. torch.Size([128])
feature_extractors.7.lin2.0.weight ...................................................................... torch.Size([128, 128])
feature_extractors.7.lin3.0.weight ...................................................................... torch.Size([128, 128])
after_conv.0.weight ..................................................................................... torch.Size([128, 128])
after_conv.0.bias ............................................................................................ torch.Size([128])
final_lin.0.weight ........................................................................................ torch.Size([1, 128])
final_lin.0.bias ............................................................................................... torch.Size([1])
| 07-01 16:47:54 Parameters Count: 1334286, Trainable: 1334286
| 07-01 16:48:01 load dataset: ego_small
200
| 07-01 16:48:08 epoch: 000| time: 7.0s| train loss: +8.848e+01 | test loss: +3.868e+01 | 
| 07-01 16:48:08 epoch: 000| train loss i: nan test loss i: nan | 
| 07-01 16:48:08 epoch: 000| time: 7.0s| train loss: +8.848e+01 | test loss: +3.868e+01 | 
| 07-01 16:48:08 epoch: 000| train loss i: nan test loss i: nan | 
| 07-01 16:48:18 epoch: 001| time: 9.7s| train loss: +4.281e+01 | test loss: +2.735e+01 | 
| 07-01 16:48:18 epoch: 001| train loss i: nan test loss i: nan | 
| 07-01 16:48:18 epoch: 001| time: 9.8s| train loss: +4.281e+01 | test loss: +2.735e+01 | 
| 07-01 16:48:18 epoch: 001| train loss i: nan test loss i: nan | 
| 07-01 16:48:29 epoch: 002| time: 11.0s| train loss: +3.218e+01 | test loss: +3.368e+01 | 
| 07-01 16:48:29 epoch: 002| train loss i: nan test loss i: nan | 
| 07-01 16:48:29 epoch: 002| time: 11.0s| train loss: +3.218e+01 | test loss: +3.368e+01 | 
| 07-01 16:48:29 epoch: 002| train loss i: nan test loss i: nan | 
