
# the output files will be stored in the directory <exp_dir>/<exp_name>
exp_dir: exp
exp_name: ego_small

seed: 1234

dataset:
  dataset_size: 200  # the maximal loaded dataset size
  max_node_num: 18
  name: ego_small  # name of the dataset, the pickle file should be data/<name>.pkl

mcmc:  # hyper parameters in the Langevin MC sampling
  eps:
  - 0.1
  - 1.0
  fixed_node_number: true
  grad_step_size:
  - 0.05
  - 0.005
  - 0.0005
  name: langevin
  step_num: 1000
model:
  name: ppgn  # the name of the score-network, should be one of ['gnn', 'mlp', 'cov', 'unet', 'edp-gnn']
  models:
    model_1:
      dropout_p: 0.0
      gnn_hidden_num_list:  # feature number for each EDP-GNN layer
      - 16
      - 16
      - 16
      - 16
      feature_nums:  # F_i
      - 16
      - 16
      - 16
      - 16
      - 16
      channel_num_list:  # C_i
      - 2
      - 4
      - 4
      - 4
      - 2
      name: ppgn  # the name of the GNN, should be one of ['gin', 'gcn']
      use_norm_layers: false
  stack_num: 1

sample:
  batch_size: 32

test:
  batch_size: 32
  split: 0.2

train:
  batch_size: 32

  lr_dacey: 0.999
  lr_init: 0.001
  momentum: 0.9

  max_epoch: 4500
  sample_interval: 1  # run sampling after <sample_interval> epochs
  save_interval: 1 # save the model after <save_interval> epochs

  shuffle: true
  sigmas:
  - 0.0
  - 0.0333
  - 0.0667
  - 0.1
  - 0.1333
  - 0.1667
  - 0.2
  - 0.2333
  - 0.2667
  - 0.3
  - 0.3333
  - 0.3667
  - 0.4
  - 0.4333
  - 0.4667
  - 0.5
  
  
  

  weight_decay: 0.0

num_layers: 6
hidden: 24
hidden_final: 24
dropout: 0.000001
n_nodes: 18
normalization: instance
noise_mlp: true

eval_from: 0
samplesize: 128
weighted: true